{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dicom\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import math\n",
    "from matplotlib import path\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.misc import imresize\n",
    "from skimage.measure import find_contours\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 512\n",
    "NB_EPOCH = 1000\n",
    "AUG_CONTOUR_NUM = 10\n",
    "AUG_TRANSFORM_NUM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atherosclerosis\n",
      " 98.61%\n",
      "calcinosis\n",
      " 97.67%\n",
      "cardiomegaly_mild\n",
      " 98.18%\n",
      "cardiomegaly_modsev\n",
      " 96.00%\n",
      "normal\n",
      " 98.67%\n",
      "tortuous_aorta\n",
      " 98.28%\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "masks_prefix = \"/home/a.kondyukov/data/Indianapolis_masks_new/\"\n",
    "cases = [\"atherosclerosis\", \"calcinosis\", \"cardiomegaly_mild\", \"cardiomegaly_modsev\", \"normal\", \"tortuous_aorta\"]\n",
    "\n",
    "for i, case in enumerate(cases):\n",
    "    filenames = !ls /home/a.kondyukov/data/Indianapolis_masks_new/\"$case\"\"_masks\" | grep \"\\.png$\"\n",
    "    \n",
    "    print(case)\n",
    "    print(\"\\r\", \"0%\", end=\"\")\n",
    "    \n",
    "    max_iter = len(filenames)\n",
    "    for j, filename in enumerate(filenames):\n",
    "        print(\"\\r\", \"%.2f\" % (j / max_iter * 100) + \"%\", end=\"\")\n",
    "        ref_img = plt.imread(os.path.join(masks_prefix, case + \"_masks\", filename))\n",
    "        cur_img = imresize(ref_img, [IMAGE_SIZE, IMAGE_SIZE])[:, :, :3].mean(axis=2)\n",
    "        X.append(cur_img)\n",
    "        Y.append(i)\n",
    "    print()\n",
    "        \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "X /= X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99.70%"
     ]
    }
   ],
   "source": [
    "contours = []\n",
    "labels = []\n",
    "\n",
    "f = np.vectorize(math.atan)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                    featurewise_center=False,\n",
    "                    featurewise_std_normalization=False,\n",
    "                    rotation_range=10.,\n",
    "                    zoom_range=0.1,\n",
    "                    width_shift_range=0.1,\n",
    "                    height_shift_range=0.1,\n",
    "                    fill_mode='constant',\n",
    "                    cval=0.,\n",
    "                    horizontal_flip=False)\n",
    "\n",
    "print(\"\\r\", \"0%\", end=\"\")\n",
    "max_iter = len(X)\n",
    "\n",
    "eps = 1e-7\n",
    "\n",
    "for counter, (mask, label) in enumerate(zip(X, Y)):\n",
    "    print(\"\\r\", \"%.2f\" % (counter / max_iter * 100) + \"%\", end=\"\")\n",
    "    for trans_counter, mask_aug in enumerate(datagen.flow(mask[None, None, :, :], batch_size=1)):\n",
    "        if trans_counter > AUG_TRANSFORM_NUM:\n",
    "            break\n",
    "        \n",
    "        cur_contours = find_contours(mask_aug[0, 0], 0.1)\n",
    "\n",
    "        areas = []\n",
    "        for i, contour in enumerate(cur_contours):\n",
    "            area = cv2.contourArea(contour[:, None, :].astype(int))\n",
    "            areas.append(area)\n",
    "\n",
    "        idx = np.argsort(areas)[:-3:-1]\n",
    "        contours_filt = [cur_contours[i] for i in range(len(cur_contours)) if i in idx]\n",
    "        if contours_filt[0][:, 1].max() < contours_filt[1][:, 1].max():\n",
    "            contours_filt = contours_filt[::-1]\n",
    "\n",
    "\n",
    "        for aug in range(AUG_CONTOUR_NUM):\n",
    "            rand_idx = np.random.choice(np.arange(contours_filt[0].shape[0]), 200, replace=False)\n",
    "            rand_idx.sort()\n",
    "            arr_left = contours_filt[0][rand_idx]\n",
    "            arr_left = arr_left[1:, :] - arr_left[:-1, :]\n",
    "    #         arr_left = f(arr_left[:, 0] / arr_left[:, 1])\n",
    "            arr_left = np.vstack([\n",
    "                f(arr_left[:, 0] / (arr_left[:, 1] + eps)),\n",
    "                np.sqrt(np.square(arr_left[:, 0]) + np.square(arr_left[:, 1]))\n",
    "                ]).T\n",
    "\n",
    "            rand_idx = np.random.choice(np.arange(contours_filt[1].shape[0]), 200, replace=False)\n",
    "            rand_idx.sort()\n",
    "            arr_right = contours_filt[1][rand_idx]\n",
    "            arr_right = arr_right[1:, :] - arr_right[:-1, :]\n",
    "    #         arr_right = f(arr_right[:, 0] / arr_right[:, 1])\n",
    "            arr_right = np.vstack([\n",
    "                f(arr_right[:, 0] / (arr_right[:, 1] + eps)),\n",
    "                np.sqrt(np.square(arr_right[:, 0]) + np.square(arr_right[:, 1]))\n",
    "                ]).T\n",
    "\n",
    "            contours.append([arr_left, arr_right])\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contours = np.array(contours)\n",
    "labels = pd.get_dummies(np.array(labels)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_idx, validate_idx = train_test_split(np.arange(len(contours)))\n",
    "\n",
    "np.savez_compressed(\"train_test_split\", train_idx=train_idx, validate_idx=validate_idx)\n",
    "X_train, X_validate = contours[train_idx], contours[validate_idx]\n",
    "Y_train, Y_validate = labels[train_idx], labels[validate_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez_compressed(\"tmpXY\", X_train=X_train, X_validate=X_validate, Y_train=Y_train, Y_validate=Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XY_file = np.load(\"tmpXY.npz\")\n",
    "X_train = XY_file[\"X_train\"]\n",
    "X_validate = XY_file[\"X_validate\"]\n",
    "Y_train = XY_file[\"Y_train\"]\n",
    "X_validate = XY_file[\"X_validate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Dense(1024, activation=\"relu\", input_shape=(796, )))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(LSTM(1024, return_sequences=True, input_shape=(398, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(1024))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(1024))\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "\n",
    "# X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "# X_validate = X_validate.reshape(X_validate.shape[0], -1)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2], X_train.shape[3])\n",
    "X_validate = X_validate.reshape(X_validate.shape[0], X_validate.shape[1] * X_validate.shape[2], X_validate.shape[3])\n",
    "\n",
    "ref_shape_train = X_train.shape\n",
    "ref_shape_validate = X_validate.shape\n",
    "\n",
    "X_train = sc.fit_transform(X_train.reshape([ref_shape_train[0], -1])).reshape(ref_shape_train)\n",
    "X_validate = sc.transform(X_validate.reshape([ref_shape_validate[0], -1])).reshape(ref_shape_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81180 samples, validate on 27060 samples\n",
      "Epoch 1/1000\n",
      " 2176/81180 [..............................] - ETA: 3139s - loss: 1.8596 - acc: 0.2063"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, \n",
    "          batch_size=128, \n",
    "          nb_epoch=NB_EPOCH, \n",
    "          validation_data=(X_validate, Y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = model.predict_classes(sc.transform(X_validate.reshape(-1, 198)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = np.argmax(Y_validate, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(t == pred).mean()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
